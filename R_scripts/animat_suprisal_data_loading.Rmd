---
title: "animat_analysis"
author: "Christian Stenbro"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
version
```


## 1. Set-up

```{r set-up}
# Loading packages:
pacman::p_load(ggplot2,
               tidyverse,
               arrow,
               animation,
               magick)
```


```{r loading data}

# Loading time-step data from task 4:
ts_data <- read_csv("/Users/christianstenbro/AU/3_sem/Perception_and_Action/Integrated Information Theory/phi-surprisal/processed_data/timestep_data_task4.csv")

# Attempting to convert to a different format:
#write_feather(ts_data, "/Users/christianstenbro/Programming/perception_action_exam/data/ts_data_feather")

# Reading from the feather file:
#ts_data_feather <- read_feather("/Users/christianstenbro/Programming/perception_action_exam/data/ts_data_feather")

# Comparing dimensions:
#dim(ts_data_feather)
#dim(ts_data)

#ts_data <- data.table(ts_data)

#identical(ts_data_feather, ts_data) # Yet they are not identical . . .

# For now, I will stick with the original data, but this is not a closed issue.

#dim(ts_data_trial_127)
```

```{r Sampling a portion of the data for experimentation}

# Sampling a portion of the data
ts_data %>% filter(Phi > max(Phi)-mean(Phi))

max(ts_data$Phi)

# Filtering out data points for trial 127. Notice that we still have data for all agents.
ts_data_trial_127 <- ts_data %>% filter(trial == 127)

# Checking the Phi range for all data in trial 127:
range(ts_data_trial_127$Phi)

# Selecting the data for agent 0, trial 127:
agent_0_ts_data_trial_127 <- ts_data_trial_127 %>% filter(agent == 0) %>% select(trial, run, agent, timestep, M1, M2, block_movement, task_type, block_size, Phi, first_sight)
```
## 2. Animating animats

### 2.1 Creating movement matrices

```{r Generalizing the above into a function}

movement_matrix <- function(data_input, trial_input, agent_input) {
  
  selected_data <- filter(data_input, trial == trial_input & agent == agent_input)

  unique_runs <- unique(selected_data$run)

  movement_coordinates_dataframe <- data.frame(timestep = unique(selected_data$timestep))

  for (run_id in unique_runs) {
    run_data <- subset(selected_data, run == run_id)
    movement_coordinates <- cumsum(run_data$M2 - run_data$M1)
    movement_coordinates_dataframe[[as.character(run_id)]] <- movement_coordinates
  }

return(movement_coordinates_dataframe)
}

# Trying out the function:
movement_matrix_1 <- movement_matrix(data_input = ts_data, 
                trial_input = 127, 
                agent_input = 5)

```

### 2.2 Animating the movement matrices

```{r Working animation script}

### Let's assemble a complete data frame of agent movement:

# Extracting data from a movement_matrix:
movement_run_0 <- movement_matrix_1[2]

# Manually defining the coordinates for all animat body parts:
x_center <- movement_run_0
x_left <- movement_run_0 - 1
x_right <- movement_run_0 + 1

y <- as.vector(rep(1, 33))

animat_0_movement <- data.frame(c(x_left, x_center, x_right), y, y, y)

### Now let's make a loop that plots this row wise:

# Converting the data frame with animat movement into a list of simple x y coordinate system for each time step:

time_step_list <- list()

for (ts in 1:nrow(animat_0_movement)) {
  x <- gather(animat_0_movement[ts, 1:3])[,2] + 8 # adding 8 to center
  y <- gather(animat_0_movement[ts, 4:6])[,2]
  x_y_coordinates <- tibble(x, y)
  
  time_step_list[[ts]] <- x_y_coordinates
}

# This is perfect: Now, we can access the coordinates from the animat_movement object in a neat (plottable) way:
time_step_list[[2]]
animat_0_movement[2,] # These are identical, except one has been centered geometrically (by adding 8).

######## Plotting and saving as a GIF file:

# First, we define the size of the grid:
grid_width <- 16
grid_height <- 35

# Then, we create a data frame with grid coordinates:
grid_data <- expand.grid(x = 1:grid_width, y = 1:grid_height)

# Then, we construct a for-loop to plot the animats

list_of_plots <- list()

for (i in seq_along(time_step_list)) {
  
  gg <- ggplot(grid_data, aes(x, y)) +
    geom_tile(color = "black", fill = "white") +
    scale_x_continuous(expand = c(0, 0), breaks = 1:grid_width) +
    scale_y_continuous(expand = c(0, 0), breaks = 1:grid_height) +
    coord_fixed(ratio = 1) +
    theme_minimal() +
    theme(axis.text = element_blank(), 
          axis.ticks = element_blank(),
          plot.title = element_text(size = 10)) +
    geom_tile(data = time_step_list[[i]], 
              aes(x, y), fill = "blue", color = "black") +
    ggtitle(paste("time_step = ", i))
  
  list_of_plots[[i]] <- gg
}

### Saving plots in a gif_file:

generate_gif_filename <- function(prefix = "animation", extension = "gif") {
  timestamp <- format(Sys.time(), "%Y%m%d%H%M%S")
  paste0(prefix, "_", timestamp, ".", extension)
}

gif_file <- generate_gif_filename(prefix = "animation", extension = "gif")

output_directory <- "/Users/christianstenbro/Programming/perception_action_exam/animation_folder"

full_path <- file.path(output_directory, gif_file)

# Save the plots as a GIF. Note that interval sets the delay for each frame in the git. Here, it is set to 0.3 seconds.
saveGIF({
  for (i in seq_along(list_of_plots)) {
    print(list_of_plots[[i]])
  }
}, movie.name = full_path, interval = 0.3, ani.width = 800, ani.height = 600)
  
```

## 3. Animating falling blocks

### 3.1 Understanding the data frame

- There are 128 trials tested on each animat (called agent in the data frame)

- In task 4, these trials correspond to:

    - 16 initial block positions
    - 2 movement directions
    - 4 different block sizes
    
- This makes 128 combinations (neat).

Additionally we know that:

- For each animat, we have 100 runs pr. trial. 

- There are 33 time steps in each run.

This means that for each agent, there will be 128 × 100 × 33 = 422,400 data points:

```{r}
128*100*33
nrow(ts_data %>% filter(agent == 0))
```

Which is indeed verified via the above filtering operation.

All in all, we should have (128 × 100 × 33) × 121 data points for the entire data frame. Here, 121 corresponds to the number of agents (animats). Do note that we have 121 as one agent is labeled 0. This results in a total of 51,110,400 observations!

```{r}
128*100*33*121
nrow(ts_data)

range(ts_data$run)
```

### 3.2 Infering the starting position of each block

We cannot completely know the block position in each trial from the information given in Albantakis et al., 2014. But if we start by assuming a pattern, we can see how it looks and whether this fits our expectation. 

First, let's try out some filtering (this sometimes exhausts the memory, possibly due to the piping structure):

```{r}

# Filtering out trials corresponding to block sizes:

block_3_data <- ts_data %>% filter(agent == 0, run == 1, block_size == 3) %>% select(run, trial, task_type, block_size, perfect_run)

block_4_data <- ts_data %>% filter(agent == 0, run == 1, block_size == 4) %>% select(run, trial, task_type, block_size, perfect_run)

block_5_data <- ts_data %>% filter(agent == 0, run == 1, block_size == 5) %>% select(run, trial, task_type, block_size, perfect_run)

block_6_data <- ts_data %>% filter(agent == 0, run == 1, block_size == 6) %>% select(run, trial, task_type, block_size, perfect_run)

# Examining trial number <-> block_size relation-ship

cat(
  "Block size 3, trial range: ", range(unique(block_3_data$trial)),
  "\nBlock size 4, trial range: ", range(unique(block_4_data$trial)), 
  "\nBlock size 5, trial range: ", range(unique(block_5_data$trial)), 
  "\nBlock size 6, trial range: ", range(unique(block_6_data$trial))
  )
```
Surprisingly, trial 96:127 corresponds to block size 5, not 6 as we might have expected.

```{r}
# Examining movement directions

ts_data %>% filter(agent == 0, run == 1, block_size == 3, trial == 0:15) %>% select(block_movement, block_size)
ts_data %>% filter(agent == 0, run == 1, block_size == 3, trial == 16:31) %>% select(block_movement, block_size)

ts_data %>% filter(agent == 0, run == 1, block_size == 4, trial == 32:47) %>% select(block_movement, block_size) 
ts_data %>% filter(agent == 0, run == 1, block_size == 4, trial == 48:63) %>% select(block_movement, block_size) 

ts_data %>% filter(agent == 0, run == 1, block_size == 5, trial == 96:111) %>% select(block_movement, block_size) 
ts_data %>% filter(agent == 0, run == 1, block_size == 5, trial == 112:127) %>% select(block_movement, block_size) 

ts_data %>% filter(agent == 0, run == 1, block_size == 6, trial == 64:79) %>% select(block_movement, block_size) 
ts_data %>% filter(agent == 0, run == 1, block_size == 6, trial == 80:95) %>% select(block_movement, block_size) 

```

Based on the above information, we can begin to see a pattern:

    Block size 3, trial range:  0-31 
    Block size 4, trial range:  32-63 
    Block size 5, trial range:  96-127 
    Block size 6, trial range:  64-95

For each of these ranges, the first half is dedicated to left-moving blocks and the second half is dedicated to right-moving blocks. Let's write this up as well:

    Block size 3
      trial 0-15: moving left (-1)
      trial 16-31: moving right (+1)

    Block size 4
      trial 32-47: moving left (-1)
      trial 48-63: moving right (+1)

    Block size 5
      trial 96-111: moving left (-1)
      trial 112-127: moving right (+1)
      
    Block size 6
      trial 64-79: moving left (-1)
      trial 80-95: moving right (+1)

The last step of the puzzle are the starting positions. Let us assume that both the animat and the blocks start in the same position:

*ts_1*
Animat position: x = 0, y = 1
Block position: x = 0, y = 1

For the next time step (ts_2) in trial 0:15, this would mean the following transformation in the block position:

*ts_2*
Animat position: x = ?, y = 1
Block position: x = -1, y = 1

Alternatively, for the next step i trial 16:31, this would mean:

*ts_2*
Animat position: x = ?, y = 1
Block position: x = 1, y = 1

We can now try out animations with an arbitrary starting point. Notice that the starting position is indeed arbitrary (or at least relative) as the walls 'wrap' - there are 'periodic bounding conditions on the vertical walls'. (Albantakis et al., 2014)

### 3.3 Animating blocks

#### 3.3.a Toy example

We will use the animation of the animat in the grid as a starting point:

```{r Trying out falling block animation}

grid_width <- 16
grid_height <- 35
grid_data <- expand.grid(x = 1:grid_width, y = 1:grid_height)

agent_data_1 <- data.frame(x = c(8, 9, 10), y = c(35,35,35))
agent_data_2 <- data.frame(x = (c(8, 9, 10)-1), y = c(34,34,34))

ggplot(grid_data, aes(x, y)) +
  geom_tile(color = "black", fill = "white") +
  scale_x_continuous(expand = c(0, 0), breaks = 1:grid_width) +
  scale_y_continuous(expand = c(0, 0), breaks = 1:grid_height) +
  coord_fixed(ratio = 1) +
  theme_minimal() +
  theme(axis.text = element_blank(), 
        axis.ticks = element_blank(),
        plot.title = element_text(size = 10)) +
  geom_tile(data = agent_data_2, aes(x, y), fill = "blue", color = "black") +
  ggtitle(paste("time_step = ", i))

```

The above chunk demonstrates the basic principles.

The task now is to construct a movement matrix for the blocks similar to the one constructed for the animats.

Let's see how much of the script can be re-used:

```{r}
# Examining the output from the movement_matrix function:

movement_matrix(data_input = ts_data, 
                trial_input = 127, 
                agent_input = 5)

```

Here, movements for a specific animat family (agent_input) in all 100 runs (0-99) along the x-axis are plotted for each time step (row-wise). 

The difference for the blocks are that we need the movement instructions for two axes: The horizontal (x-axis) and the vertical (y-axis). 

There is, however, way less complexity to the movement of the blocks, which simplifies our task; for each time step, they consistently move one pixel down and one pixel to the left or right. This has been verified by the data examination in point 3.1-3.2.

#### 3.3.b Writing a function for extracting block movement information and block size

```{r}

# Parameters:

# $block_size (dbl)
# $block_movement (dbl)
# $task_type (chr)

# Designing a new function for extracting block movements:
block_movement_matrix <- function(data_input, trial_input, agent_input) {
  
  selected_data <- filter(data_input, trial == trial_input & agent == agent_input)
  unique_runs <- unique(selected_data$run)
  movement_coordinates_dataframe <- data.frame(timestep = unique(selected_data$timestep))

  for (run_id in unique_runs) {
    run_data <- subset(selected_data, run == run_id)
    block_movement_coordinates <- cumsum(run_data$block_movement)
    movement_coordinates_dataframe[[as.character(run_id)]] <- block_movement_coordinates
  }

return(movement_coordinates_dataframe)
}

# Writing a small block_size + task_type function:
block_size <- function(data_input, trial_input, agent_input, run_input) {
  selected_data <- filter(data_input, trial == trial_input, agent == agent_input)
  return(unique(selected_data$block_size))
}

# Trying out the functions:
block_movement_matrix(data_input = ts_data, 
                trial_input = 1, 
                agent_input = 0)

block_size(data_input = ts_data, 
            trial_input = 1, 
            agent_input = 0)

# Note that the block_size is independent by the run - it is purely determined by the type of trial.
```

### 3.4 Making more economic functions

```{r}
# Block size:
block_size_2 <- function(data_subset_input) {
  return(unique(data_subset_input$block_size))
}

# Animat movement matrix:
animat_movement_matrix_2 <- function(data_subset_input) {
  unique_runs <- unique(data_subset_input$run)
  movement_coordinates_dataframe <- data.frame(
    timestep = unique(data_subset_input$timestep))

  for (run_id in unique_runs) {
    run_data <- subset(data_subset_input, run == run_id)
    movement_coordinates <- cumsum(run_data$M2 - run_data$M1)
    movement_coordinates_dataframe[[as.character(run_id)]] <- movement_coordinates
  }
return(movement_coordinates_dataframe)
}

# Block movement matrix:
block_movement_matrix_2 <- function(data_subset_input) {
  unique_runs <- unique(data_subset_input$run)
  movement_coordinates_dataframe <- data.frame(
    timestep = unique(data_subset_input$timestep))

  for (run_id in unique_runs) {
    run_data <- subset(data_subset_input, run == run_id)
    block_movement_coordinates <- cumsum(run_data$block_movement)
    movement_coordinates_dataframe[[as.character(run_id)]] <- block_movement_coordinates
  }
return(movement_coordinates_dataframe)
}

# Starting position
starting_position <- function(input_trial) {
  cycle_length <- 16
  return((input_trial %% cycle_length))
}
```


Now, we can combine the two functions (here they are still separated but they could easily be put together):

## 4. Combining the functions for block and animat movement

### 4.1 Starting position function

Let us also write a small starting position function. We assume that starting positions cycle from 0 to 16:

0:15
16:31

32:47 
48:63

64:79
80:95

96:111
112:127


### 4.2 Working animation!!!

```{r Filtering the data looking for interesting runs}
filter(ts_data, trial == 22 & Phi > 0) %>% filter(run == 49, agent == 52)
```

```{r Setting parameters}
t = 24
a = 80
r = 80
```

```{r Sub-setting data and defining temporary objects}
# Allocating more memory:
memory.limit(size = 12000)

# Sub-setting the data according to the selected parameters:
subset_all_runs <- filter(ts_data, trial == t & agent == a)
subset_specific_run <- subset_all_runs %>% filter(run == r)
```

```{r Extracting first-sight event}
first_sight_vec <- subset_specific_run %>% select(subset_specific_run$first_sight)

for (i in 1:nrow(first_sight)) {
  if (first_sight[[i,1]] == 1) {
    first_sight_event <- i
  }
}
```

```{r Defining/printing identifiers and variables:}
task_type <- subset_all_runs$task_type[1]
set_starting_position <- starting_position(input_trial = t)
run <- (r)+2
num_dimensions <- block_size_2(data_subset_input = subset_all_runs)
avg_phi <- mean(subset_specific_run$Phi)
avg_surprisal <- mean(subset_specific_run$surprisal)

# Printing selected information:
cat("Starting position =", set_starting_position, 
    "\nBlock size =", num_dimensions,
    "\nTask type", paste0("'",task_type, "'"),
    "\nFirst sight event at timestep", first_sight_event,
    "\nAvg. phi (3 digits) =", round(avg_phi, 3),
    "\nAvg. surprisal (3 digits) =", round(avg_surprisal, 3)
    )
```

```{r Extracting the animat and block movement matrices using previously defined functions}
# Extracting movement matrices
bmm <- block_movement_matrix_2(data_subset_input = subset_all_runs)
amm <- animat_movement_matrix_2(data_subset_input = subset_all_runs)
```

```{r Computing visualization data frame for the animat movement}
# First, extract movement from a specific run:
movement_run_0 <- amm[run]

# Adding a 0th step and end-state step:
starting_state <- 0
end_state <- movement_run_0[nrow(movement_run_0), 1]
movement_run_0 <- rbind(starting_state, movement_run_0, end_state)

# Manually defining the coordinates for all animat body parts:
x_1 <- movement_run_0
x_2 <- movement_run_0 + 1
x_3 <- movement_run_0 + 2
y <- as.vector(rep(1, nrow(movement_run_0)))
animat_0_movement <- data.frame(c(x_1, x_2, x_3), y, y, y)

# Converting the data frame with animat movement into a list of simple x y coordinate system for each time step:

time_step_list <- list()

for (ts in 1:nrow(animat_0_movement)) {
  x <- gather(animat_0_movement[ts, 1:3])[,2] + set_starting_position
  y <- gather(animat_0_movement[ts, 4:6])[,2]
  x <- ((x + 16) %% 16 + 1)
  #print(x)
  x_y_coordinates <- tibble(x, y)
  time_step_list[[ts]] <- x_y_coordinates
}

# This is perfect: Now, we can access the coordinates from the animat_movement object in a neat (plottable) way as a function of the time-step. 
#time_step_list[[2]]
```

```{r Computing visualization data frame for the block movement}
block_movement_run_0 <- bmm[run]

# Extracting end-state information
if (block_movement_run_0[nrow(block_movement_run_0), 1] > 0) {
  end_state_block <- block_movement_run_0[nrow(block_movement_run_0), 1]+1
} else {
  end_state_block <- block_movement_run_0[nrow(block_movement_run_0), 1]-1
}

# Adding a 0th step and end-state step:
block_movement_run_0 <- rbind(0, block_movement_run_0, end_state_block)

# This already corresponds to the x-axis movement. Now we need to extend the block according to its block_size:
block_x_movement <- as.data.frame(
  sapply(1:num_dimensions, function(dim) block_movement_run_0 + (dim - 1)))

colnames(block_x_movement) <- paste0("x", 1:num_dimensions)

# How to construct y-axis movement? This is just a vector with descending values from 35 to 1:
empty_data_frame <- data.frame(matrix(nrow=0, ncol = num_dimensions))

#empty_data_frame <- rbind(c(rep(34, num_dimensions)), empty_data_frame) # This will be the 0th step - before we have timestep data . . .

for (i in 1:35) {
  empty_data_frame[i,] <- c(rep(36-i, num_dimensions)) # here, the grid height is used as the starting value
}
colnames(empty_data_frame) <- paste0("y", 1:num_dimensions)
block_y_movement <- empty_data_frame
block_y_movement <- block_y_movement

# Combining x and y movement
block_movement_x_y <- data_frame(block_x_movement, block_y_movement)

# Converting these into a list of vectors for each entry in the time step series:
block_time_step_list <- list()

for (ts in 1:nrow(block_movement_x_y)) {
  x <- pivot_longer(block_movement_x_y[ts, 1:num_dimensions], cols = everything())$value
  y <- pivot_longer(block_movement_x_y[ts, (num_dimensions + 1):(num_dimensions * 2)], cols = everything())$value
  
  # Adding wall wrapping for x-coordinates
  x <- ((x + 16) %% 16 + 1)
  #print(x)
  block_x_y_coordinates <- tibble(x, y)
  block_time_step_list[[ts]] <- block_x_y_coordinates
}

```

```{r combining animat and box movement plots}
# Defining grid:
grid_width <- 16
grid_height <- 35

# Then, we create a data frame with grid coordinates:
grid_data <- expand.grid(x = 1:grid_width, y = 1:grid_height)

# Then, we construct a for loop to plot the animats
list_of_plots <- list()

for (i in seq_along(block_time_step_list)) {
  
  gg <- ggplot(grid_data, aes(x, y)) +
    geom_tile(color = "black", fill = "beige") +
    scale_x_continuous(expand = c(0, 0), breaks = 1:grid_width) +
    scale_y_continuous(expand = c(0, 0), breaks = 1:grid_height) +
    coord_fixed(ratio = 1) +
    theme_minimal() +
    theme(axis.text = element_blank(), 
          axis.ticks = element_blank(),
          plot.title = element_text(size = 10)) +
    geom_tile(data = block_time_step_list[[i]], 
              aes(x, y), fill = "orange", color = "black", alpha = 0.8) +
    geom_tile(data = time_step_list[[i]], 
              aes(x, y), fill = "blue", color = "black", alpha = 0.8) +
    ggtitle(paste("time_step = ", i-1))
  
  list_of_plots[[i]] <- gg
}

#list_of_plots
```

```{r}
### Saving plots in a gif_file:
generate_gif_filename <- function(prefix = "animation", extension = "gif") {
  identifier <- paste0("trial", t, "_", 
                       "agent", a, "_", 
                       "run", r, "_", 
                       "sight", first_sight_event, "_", 
                       "task", task_type, "_", 
                       "startpos", set_starting_position, "_", 
                       "phi", avg_phi, "_", 
                       "srpr", avg_surprisal
                       )
  
  paste0(prefix, "_", identifier, ".", extension)
}

gif_file <- generate_gif_filename(prefix = "animation", extension = "gif")

output_directory <- "/Users/christianstenbro/Programming/perception_action_exam/animation_folder"

full_path <- file.path(output_directory, gif_file)

# Saving the plots as a GIF. Note that interval sets the delay for each frame in the git. Here, it is set to 0.3 seconds.
saveGIF({
  for (i in seq_along(list_of_plots)) {
    print(list_of_plots[[i]])
  }
}, movie.name = full_path, interval = 0.3, ani.width = 600, ani.height = 800)
  
```

## 5. Animation function experiment


```{r}
subset_all_runs
subset_specific_run
subset_specific_run$first_sight

1:nrow(first_sight_vec)

first_sight_vec[4]

1:length(first_sight_vec)
```

```{r Defining the function}
animating_animat <- function(input_data, t, a, r, batch_name) {
  
subset_all_runs <- filter(ts_data, trial == t & agent == a)
subset_specific_run <- subset_all_runs %>% filter(run == r)

# Extracting first-sight event:
first_sight_vec <- subset_specific_run$first_sight

for (i in 1:length(first_sight_vec)) {
  if (first_sight_vec[i] == 1) {
    first_sight_event <- i
  }
}

# Defining/printing identifiers and variables:}
task_type <- subset_all_runs$task_type[1]
set_starting_position <- starting_position(input_trial = t)
run <- (r)+2
num_dimensions <- block_size_2(data_subset_input = subset_all_runs)
avg_phi <- mean(subset_specific_run$Phi)
avg_surprisal <- mean(subset_specific_run$surprisal)

# Printing selected information:
cat("Starting position =", set_starting_position, 
    "\nBlock size =", num_dimensions,
    "\nTask type", paste0("'",task_type, "'"),
    "\nFirst sight event at timestep", first_sight_event,
    "\nAvg. phi (3 digits) =", round(avg_phi, 3),
    "\nAvg. surprisal (3 digits) =", round(avg_surprisal, 3)
    )

# Extracting movement matrices
bmm <- block_movement_matrix_2(data_subset_input = subset_all_runs)
amm <- animat_movement_matrix_2(data_subset_input = subset_all_runs)

### Computing visualization data frame for the animat movement}

# First, extract movement from a specific run:
movement_run_0 <- amm[run]

# Adding a 0th step and end-state step:
starting_state <- 0
end_state <- movement_run_0[nrow(movement_run_0), 1]
movement_run_0 <- rbind(starting_state, movement_run_0, end_state)

# Manually defining the coordinates for all animat body parts:
x_1 <- movement_run_0
x_2 <- movement_run_0 + 1
x_3 <- movement_run_0 + 2
y <- as.vector(rep(1, nrow(movement_run_0)))
animat_0_movement <- data.frame(c(x_1, x_2, x_3), y, y, y)

# Converting the data frame with animat movement into a list of simple x y coordinate system for each time step:

time_step_list <- list()

for (ts in 1:nrow(animat_0_movement)) {
  x <- gather(animat_0_movement[ts, 1:3])[,2] + set_starting_position
  y <- gather(animat_0_movement[ts, 4:6])[,2]
  x <- ((x + 16) %% 16 + 1)
  #print(x)
  x_y_coordinates <- tibble(x, y)
  time_step_list[[ts]] <- x_y_coordinates
}

# This is perfect: Now, we can access the coordinates from the animat_movement object in a neat (plottable) way as a function of the time-step. 
#time_step_list[[2]]

### Computing visualization data frame for the block movement}
block_movement_run_0 <- bmm[run]

# Extracting end-state information
if (block_movement_run_0[nrow(block_movement_run_0), 1] > 0) {
  end_state_block <- block_movement_run_0[nrow(block_movement_run_0), 1]+1
} else {
  end_state_block <- block_movement_run_0[nrow(block_movement_run_0), 1]-1
}

# Adding a 0th step and end-state step:
block_movement_run_0 <- rbind(0, block_movement_run_0, end_state_block)

# This already corresponds to the x-axis movement. Now we need to extend the block according to its block_size:
block_x_movement <- as.data.frame(
  sapply(1:num_dimensions, function(dim) block_movement_run_0 + (dim - 1)))

colnames(block_x_movement) <- paste0("x", 1:num_dimensions)

# How to construct y-axis movement? This is just a vector with descending values from 35 to 1:
empty_data_frame <- data.frame(matrix(nrow=0, ncol = num_dimensions))

#empty_data_frame <- rbind(c(rep(34, num_dimensions)), empty_data_frame) # This will be the 0th step - before we have timestep data . . .

for (i in 1:35) {
  empty_data_frame[i,] <- c(rep(36-i, num_dimensions)) # here, the grid height is used as the starting value
}
colnames(empty_data_frame) <- paste0("y", 1:num_dimensions)
block_y_movement <- empty_data_frame
block_y_movement <- block_y_movement

# Combining x and y movement
block_movement_x_y <- data_frame(block_x_movement, block_y_movement)

# Converting these into a list of vectors for each entry in the time step series:
block_time_step_list <- list()

for (ts in 1:nrow(block_movement_x_y)) {
  x <- pivot_longer(block_movement_x_y[ts, 1:num_dimensions], cols = everything())$value
  y <- pivot_longer(block_movement_x_y[ts, (num_dimensions + 1):(num_dimensions * 2)], cols = everything())$value
  
  # Adding wall wrapping for x-coordinates
  x <- ((x + 16) %% 16 + 1)
  #print(x)
  block_x_y_coordinates <- tibble(x, y)
  block_time_step_list[[ts]] <- block_x_y_coordinates
}

### Combining animat and box movement plots}
# Defining grid:
grid_width <- 16
grid_height <- 35

# Then, we create a data frame with grid coordinates:
grid_data <- expand.grid(x = 1:grid_width, y = 1:grid_height)

# Then, we construct a for loop to plot the animats
list_of_plots <- list()

for (i in seq_along(block_time_step_list)) {
  
  gg <- ggplot(grid_data, aes(x, y)) +
    geom_tile(color = "black", fill = "beige") +
    scale_x_continuous(expand = c(0, 0), breaks = 1:grid_width) +
    scale_y_continuous(expand = c(0, 0), breaks = 1:grid_height) +
    coord_fixed(ratio = 1) +
    theme_minimal() +
    theme(axis.text = element_blank(), 
          axis.ticks = element_blank(),
          plot.title = element_text(size = 10)) +
    geom_tile(data = block_time_step_list[[i]], 
              aes(x, y), fill = "orange", color = "black", alpha = 0.8) +
    geom_tile(data = time_step_list[[i]], 
              aes(x, y), fill = "blue", color = "black", alpha = 0.8) +
    ggtitle(paste("time_step = ", i-1))
  
  list_of_plots[[i]] <- gg
}

### Saving plots in a gif_file:
generate_gif_filename <- function(prefix = "animation", extension = "gif") {
  identifier <- paste0(input_data$stratum[s], "_",
                       "trial", t, "_", 
                       "agent", a, "_", 
                       "run", r, "_", 
                       "sight", first_sight_event, "_", 
                       "task", task_type, "_", 
                       "startpos", set_starting_position, "_", 
                       "phi", avg_phi, "_", 
                       "srpr", avg_surprisal
                       )
  
  paste0(prefix, "_", identifier, ".", extension)
}

gif_file <- generate_gif_filename(prefix = "animation", extension = "gif")

output_directory <- paste0("/Users/christianstenbro/Programming/perception_action_exam/animation_folder/", batch_name)

if (!dir.exists(output_directory)) {
    dir.create(output_directory)
  }

full_path <- file.path(output_directory, gif_file)

# Saving the plots as a GIF. Note that interval sets the delay for each frame in the git. Here, it is set to 0.3 seconds.
saveGIF({
  for (i in seq_along(list_of_plots)) {
    print(list_of_plots[[i]])
  }
}, movie.name = full_path, interval = 0.3, ani.width = 600, ani.height = 800)
  

}
```

```{r Testing the function}
animating_animat(t = 90, a = 80, r = 80, batch_name = "batch_1")
```

## 6. Creating stimuli battery for the experiment

The next step is to make a sampling mechanism for trial selection. The most important thing is that a wide spectrum of avg. phi values is selected. One way to ensure this is to:

1) Calculate avg. phi value for all trials_agents_runs. 
2) Randomly pick samples from this distribution with equidistant avg. phi values covering the entire range (within some acceptable range of deviation - we cannot expect to have exactly matching phi values). 

Reflections regarding 2): 

- It is worth considering the amount of trials for each participants. 
- It is also worth to consider whether each participants should have the exact same stimuli (corresponding to exactly the same runs across agents and trials), or whether each participant should have their own random sample (covering a similar spectrum of avg. phi values). 
- What is an acceptable deviation for avg. phi values? The data has to be binned, but in the most elegant version of this experiment, each trial is still selected semi-randomly . . .

Further thoughts regarding experimental design: 

3) The participants need to know what the task is. This can possibly be handled with some kind of splash screen between each trial. 

### 6.1 Calculating avg. phi for all runs across agents and trials

This should be possible via tidyverse pipeline operations:

```{r Calculating avg. phi}
# Grouping the data by run, agent, trial and calculating the average Phi:
ts_tibble <- tibble(ts_data)
ts_tibble <- ts_tibble %>% group_by(run, agent, trial)
avg_phi_data <- ts_tibble %>% summarise(mean(Phi), median(Phi), sd(Phi), min(Phi), max(Phi))
avg_phi_data

avg_phi_data <- avg_phi_data %>% rename(avg_phi = `mean(Phi)`, 
                                        median_phi = `median(Phi)`, 
                                        sd_phi = `sd(Phi)`,
                                        min_phi = `min(Phi)`,
                                        max_phi = `max(Phi)`)

# Visualizing the distribution of avg. Phi scores:
ggplot(avg_phi_data, aes(x = avg_phi, fill = "red")) +
  geom_density() +
  theme_minimal() +
  ggtitle("Fig. 1.1: Mean Phi distribution across all runs")

ggplot(avg_phi_data, aes(x = median_phi, fill = "red")) +
  geom_density() +
  theme_minimal() +
  ggtitle("Fig. 1.2: Median Phi distribution across all runs")

ggplot(avg_phi_data, aes(x = sd_phi, fill = "red")) +
  geom_density() +
  theme_minimal() +
  ggtitle("Fig. 1.3: SD Phi distribution across all runs")

ggplot(avg_phi_data, aes(x = min_phi, fill = "red")) +
  geom_density() +
  theme_minimal() +
  ggtitle("Fig. 1.4: Min Phi distribution across all runs")

ggplot(avg_phi_data, aes(x = max_phi, fill = "red")) +
  geom_density() +
  theme_minimal() +
  ggtitle("Fig. 1.5: Max Phi distribution across all runs")


```
Commenting on the distribution: 

While we clearly don't have a bell curve, it is still instructive for the experiment to test a wide range of phi values. This does mean that higher phi values will be heavily over-represented in the stimuli battery compared to the actual distribution. 

```{r Calculating some stats on the distribution of phi values}
# Making a boxplot:
boxplot(avg_phi_data$avg_phi, horizontal=TRUE, main = "Fig. 2: Mean Phi Scores Boxplot", xlab = "Phi")

# And descriptive statistics + range of the phi values:
cat("Range: From", range(avg_phi_data$avg_phi)[1], "to", range(avg_phi_data$avg_phi)[2], "\n\n", "Descriptive statistics:\n")
summary(avg_phi_data$avg_phi)
```
Output pasted:

Range: From 0 to 2.518749 

Descriptive statistics:

   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
0.00000 0.03304 0.18750 0.31162 0.47939 2.51875 

### 6.2 Picking samples from the trial distribution

We can now use stratified sampling:

```{r Stratified sampling according to the binned avg. phi distrubition}
# Setting seed:
#set.seed(seed = 100) # Used for generating test batches
set.seed(seed = 200) # Used for generating the experimental stimuli batch


# Defining the bins from the phi value range:
num_bins <- 10
phi_seq <- seq(min(avg_phi_data$avg_phi), max(avg_phi_data$avg_phi), length.out = num_bins + 1)

# Removing previous grouping: 
avg_phi_data <- tibble(avg_phi_data)

# Assigning unique Stratum_ID dependent on the value of phi:
avg_phi_data <- mutate(avg_phi_data, stratum = case_when(
  between(avg_phi_data$avg_phi, phi_seq[1], phi_seq[2]) ~ "Stratum_1",
  between(avg_phi_data$avg_phi, phi_seq[2], phi_seq[3]) ~ "Stratum_2",
  between(avg_phi_data$avg_phi, phi_seq[3], phi_seq[4]) ~ "Stratum_3",
  between(avg_phi_data$avg_phi, phi_seq[4], phi_seq[5]) ~ "Stratum_4",
  between(avg_phi_data$avg_phi, phi_seq[5], phi_seq[6]) ~ "Stratum_5",
  between(avg_phi_data$avg_phi, phi_seq[6], phi_seq[7]) ~ "Stratum_6",
  between(avg_phi_data$avg_phi, phi_seq[7], phi_seq[8]) ~ "Stratum_7",
  between(avg_phi_data$avg_phi, phi_seq[8], phi_seq[9]) ~ "Stratum_8",
  between(avg_phi_data$avg_phi, phi_seq[9], phi_seq[10]) ~ "Stratum_9",
  between(avg_phi_data$avg_phi, phi_seq[10], phi_seq[11]) ~ "Stratum_10"
  )
  )

# avg_phi_data %>% filter(avg_phi > phi_seq[10])
# We can notice that the very high value of phi only occurs for very specific runs (weirdly).
      
# Random sampling of runs based on the phi strata:
n_per_stratum <- 5

# Perform stratified sampling
sampled_data <- avg_phi_data %>%
  group_by(stratum) %>%
  slice_sample(n = n_per_stratum, replace = FALSE)

sampled_data
```

## 7. Visualizing stimuli battery

```{r Using looping for the visualization}
# Removing grouping:
sampled_data <- data_frame(sampled_data)

# Setting batch name (creates a folder of the same name in the animation output folder):
batch <- "batch_7"
batch_name <- paste0(batch, "_s", n_per_stratum)

# Making a for loop for visualization:
for (s in 1:nrow(sampled_data)) {
  animating_animat(input_data = sampled_data, t = sampled_data$trial[s], a = sampled_data$agent[s], r = sampled_data$run[s], batch_name = batch_name)
}

```

Block size 3, trial range:  0-31 
Block size 4, trial range:  32-63 
Block size 5, trial range:  96-127 
Block size 6, trial range:  64-95

Catch = block size 3 + 6
Avoid = block size 4 + 5


```{r Sampling from the batch ensuring balanced task type}
set.seed(seed = 200)

# Coding the task_type based on trial:
sampled_data_batch_7 <- sampled_data

sampled_data_batch_7 <- sampled_data_batch_7 %>% mutate(task_type = case_when(
    trial <= 31 ~ "Catch",
    trial > 31 & trial <= 63 ~ "Avoid",
    trial > 63 & trial <= 95 ~ "Catch",
    trial > 95 & trial <= 127 ~ "Avoid",
))

# Sampling from the batch while balancing the task_type:
final_battery <- sampled_data_batch_7 %>% group_by(stratum, task_type) %>% slice_sample(n = 1)

final_battery # Unfortunately, these are right now filtered manually from the batch

final_battery

final_battery$stratum <- factor(final_battery$stratum, levels = c("Stratum_1", "Stratum_2", "Stratum_3", "Stratum_4", "Stratum_5", "Stratum_6", "Stratum_7", "Stratum_8", "Stratum_9", "Stratum_10"))

# Plotting avg. phi structure of the final test battery:

ggplot(final_battery, aes(x = avg_phi, color = task_type)) +
  geom_density() # Note that this might not be the perfect visualization as it aggregates the already aggregated phi values.

tick_lab <- seq(1:10)

ggplot(final_battery, aes(x = final_battery$stratum, y = final_battery$avg_phi, color = final_battery$task_type)) + 
  geom_point(alpha = 0.7, size = 2) + 
  ggtitle("Fig. 3.1: Avg. Phi for each strata in the stimuli battery") +
  labs(color = "Task type") +
  xlab("Stratum") + 
  ylab("Avg. Phi") +
  scale_x_discrete(labels = tick_lab) +
  theme_minimal()

ggplot(final_battery, aes(x = final_battery$stratum, y = final_battery$sd_phi, color = final_battery$task_type)) + 
  geom_point(alpha = 0.7, size = 2) + 
  ggtitle("Fig. 3.2: Phi SD for each strata in the stimuli battery") +
  labs(color = "Task type") +
  xlab("Stratum") + 
  ylab("SD Phi") +
  scale_x_discrete(labels = tick_lab) +
  theme_minimal()

ggplot(final_battery, aes(x = final_battery$stratum, y = final_battery$median_phi, color = final_battery$task_type)) + 
  geom_point(alpha = 0.7, size = 2) + 
  ggtitle("Fig. 3.3: Median Phi for each strata in the stimuli battery") +
  labs(color = "Task type") +
  xlab("Stratum") + 
  ylab("Median Phi") +
  scale_x_discrete(labels = tick_lab) +
  theme_minimal()
```

```{r Using looping for the visualization}
# Removing grouping:
final_battery <- data_frame(final_battery)
final_battery

# Writing the data:
write_csv(final_battery, file = paste0("/Users/christianstenbro/Programming/perception_action_exam/data","/final_battery", ".csv")) 

# Setting batch name (creates a folder of the same name in the animation output folder):
batch <- "batch_9"
batch_name <- paste0(batch, "balanced")

# Making a for loop for visualization:
for (s in 1:nrow(final_battery)) {
  animating_animat(input_data = final_battery, t = final_battery$trial[s], a = final_battery$agent[s], r = final_battery$run[s], batch_name = batch_name)
}

```


Notes on batch generation: 

Batch 1-3 (test batches) generated with random seed 100
Batch 5-8 (experimental stimuli) generated with random seed 200

## 8. New approach with only 5 strata but balanced sample:

```{r Stratified sampling according to the binned avg. phi distrubition}
# Setting seed:
#set.seed(seed = 100) # Used for generating test batches
set.seed(seed = 200) # Used for generating the experimental stimuli batch

# Defining the bins from the phi value range:
num_bins <- 5
phi_seq <- seq(min(avg_phi_data$avg_phi), max(avg_phi_data$avg_phi), length.out = num_bins + 1)

# Removing previous grouping: 
avg_phi_data <- tibble(avg_phi_data)

# Assigning unique Stratum_ID dependent on the value of phi:
avg_phi_data <- mutate(avg_phi_data, stratum = case_when(
  between(avg_phi_data$avg_phi, phi_seq[1], phi_seq[2]) ~ "Stratum_1",
  between(avg_phi_data$avg_phi, phi_seq[2], phi_seq[3]) ~ "Stratum_2",
  between(avg_phi_data$avg_phi, phi_seq[3], phi_seq[4]) ~ "Stratum_3",
  between(avg_phi_data$avg_phi, phi_seq[4], phi_seq[5]) ~ "Stratum_4",
  between(avg_phi_data$avg_phi, phi_seq[5], phi_seq[6]) ~ "Stratum_5"
  )
  )

# avg_phi_data %>% filter(avg_phi > phi_seq[10])
# We can notice that the very high value of phi only occurs for very specific runs (weirdly).
      
# Random sampling of runs based on the phi strata:
n_per_stratum <- 5

# Perform stratified sampling
sampled_data <- avg_phi_data %>%
  group_by(stratum) %>%
  slice_sample(n = n_per_stratum, replace = FALSE)
```


```{r Using looping for the visualization}
# Removing grouping:
sampled_data <- data_frame(sampled_data)

# Setting batch name (creates a folder of the same name in the animation output folder):
batch <- "batch_8"
batch_name <- paste0(batch, "_s", n_per_stratum)

# Making a for loop for visualization:
for (s in 1:nrow(sampled_data)) {
  animating_animat(t = sampled_data$trial[s], a = sampled_data$agent[s], r = sampled_data$run[s], batch_name = batch_name)
}

```

Catch = block size 3 + 6

      Block size 3, trial range:  0-31 
      Block size 6, trial range:  64-95
      
Avoid = block size 4 + 5

    Block size 4, trial range:  32-63 
    Block size 5, trial range:  96-127 

```{r Sampling from the batch ensuring balanced task type}
# Coding the task_type based on trial:
sampled_data_batch_8 <- sampled_data

sampled_data_batch_8 <- sampled_data_batch_8 %>% mutate(task_type = case_when(
    trial <= 31 ~ "Catch",
    trial > 31 & trial <= 63 ~ "Avoid",
    trial > 63 & trial <= 95 ~ "Catch",
    trial > 95 & trial <= 127 ~ "Avoid",
))

sampled_data_batch_8

# Sampling (n = 10) from the batch while balancing the task_type:
n = 10

sampled_data_batch_8 %>% group_by(stratum, task_type) %>% slice_sample(n = 1)

ts_data %>% filter(run == 36, agent == 62, trial == 102)

```
```{r}
ts_data %>% filter(agent == 1)
```

