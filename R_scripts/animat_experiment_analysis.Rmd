---
title: "animat_experiment_analysis"
author: "Christian Stenbro"
date: "`r Sys.Date()`"
output: html_document
---

# Set-up

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Loading packages:
pacman::p_load(tidyverse, 
               janitor, 
               rstanarm)

# Checking versions of R and rstanarm:
version
packageVersion("rstanarm")
```

# 1. Initial Data Operations

## 1.1 Loading and cleaning data

```{r}
data <- read_csv("/Users/christianstenbro/AU/3_sem/Perception_and_Action/Projekt/Data/cleaned_betwixt_report_analysis__1086157761143229719_all_data.csv", skip=1)

# Removing the empty rows and irrelevant columns:
data <- data %>% filter(s1_catch != "NA") %>% select(-`Overall Status`, -'E-mail') # Note that no mails were collected

# Cleaning names and renaming variables:
data <- clean_names(data)
data <- data %>% rename(qualitative = how_did_you_make_your_rating_you_do_not_have_to_respond)

head(data)
```

```{r Additional cleaning}
# Adding an ID column: 
subj_id <- factor(seq(1:nrow(data)))
data <- cbind(subj_id, data)

# Transforming data frame from wide to long format:
data_long <- pivot_longer(data, names_to = "variable", cols = s1_catch:s10_avoid)
data_long <- tibble(data_long)
head(data_long)

# Adding coding for variable type:
code <- c("catch", "avoid")
task_type <- rep(code, nrow(data_long)/2)
identical(nrow(data_long), length(task_type))
data_long <- cbind(data_long, task_type)
data_long <- tibble(data_long)
head(data_long)
```
## 1.2 Initial visualizations
```{r}
# Initial visualization
tick_lab <- seq(1:length(unique(data_long$variable)))

# data_long %>% ggplot(aes(x = variable, y = value, color = subj_id)) +
#   geom_point() + 
#   facet_wrap(~task_type) +
#   scale_x_discrete(labels = tick_lab)

data_long %>% filter(task_type == "catch") %>% 
  ggplot(aes(x = variable, y = value, color = subj_id)) +
  geom_point() + 
  facet_wrap(~subj_id) +
  scale_x_discrete(labels = NULL) +
  ggtitle("Task type: catch")

data_long %>% filter(task_type == "avoid") %>% 
  ggplot(aes(x = variable, y = value, color = subj_id)) +
  geom_point() + 
  facet_wrap(~subj_id) +
  scale_x_discrete(labels = NULL) +
  ggtitle("Task type: avoid")

# data_long %>% ggplot(aes(x = variable, y = value)) +
#   geom_boxplot() +
#   scale_x_discrete(labels = tick_lab)
```
There is definitely something systematic going on, but I don't think it necessarily relates to Phi (since Phi is the organizing principle on the x-axis). At least there is no visible trend in the direction of the hypothesis. 

## 1.3 Merging the experimental data with phi statistics from the stimuli time series data
```{r Merging data frame with phi statistics and saving data objects to files}
# Loading the final battery data frame:
battery_data <- read_csv("/Users/christianstenbro/Programming/perception_action_exam/data/final_battery.csv")

# Merging with experimental data:

## Extracting variable names:
variable_names <- unique(data_long$variable)
variable <- variable_names

## Reordering battery data frame and appending variable_names:
battery_data$stratum <- factor(battery_data$stratum, levels = c("Stratum_1", 
                                                                "Stratum_2", 
                                                                "Stratum_3", 
                                                                "Stratum_4", 
                                                                "Stratum_5", 
                                                                "Stratum_6", 
                                                                "Stratum_7", 
                                                                "Stratum_8", 
                                                                "Stratum_9", 
                                                                "Stratum_10"))
battery_data <- arrange(battery_data, by = stratum, desc(task_type))

## Adding variable names for binding
battery_data <- cbind(battery_data, variable)

## Converting binding variables to factors
battery_data$variable <- factor(battery_data$variable)
levels(battery_data$variable)

data_long$variable <- factor(data_long$variable)
levels(data_long$variable)

colnames(data_long)
colnames(battery_data)

## Merging the stimuli data (statistics regarding phi for each trial) with the data from the experiment:
merged_data <- merge(data_long, battery_data, by = c("variable"))

merged_data <- merged_data %>% arrange(subj_id, variable)

merged_data <- merged_data %>% 
  select(-task_type.y) %>% 
  rename("task_type" = task_type.x) %>% 
  relocate(subj_id, .before = variable)

head(merged_data)

merged_data$stratum <- factor(merged_data$stratum, levels = c("Stratum_1", 
                                                                "Stratum_2", 
                                                                "Stratum_3", 
                                                                "Stratum_4", 
                                                                "Stratum_5", 
                                                                "Stratum_6", 
                                                                "Stratum_7", 
                                                                "Stratum_8", 
                                                                "Stratum_9", 
                                                                "Stratum_10"))
merged_data <- merged_data %>% arrange(subj_id, stratum)

merged_data <- merged_data %>% rename("phi_rating" = value)

# Saving the merged data:
write_csv(merged_data, 
          file = paste0("/Users/christianstenbro/Programming/perception_action_exam/data","/merged_data", ".csv")
          )

# Saving the qualitative ratings:
qualitative_statements <- unique(merged_data$qualitative)[2:11] # the first row is NA

write(qualitative_statements, 
          file = paste0("/Users/christianstenbro/Programming/perception_action_exam/data","/qualitative_statements", ".txt")
      )
```

## 1.4 Plotting consciousness ratings (named phi_rating in the data frame) against actual avg_phi value

```{r}
# GG plot visualizations:
merged_data %>% 
  ggplot(aes(x = avg_phi, y = phi_rating, color = task_type)) +
  geom_point() + 
  ggtitle("")

merged_data %>% 
  ggplot(aes(x = phi_rating)) +
  geom_density()
```

# 2. Fitting Linear Regression Models

In this section, different linear regression models are fitted to gain an estimate of systematic variation in the rating of phi according to the actual value of phi for each observation (individual rating) in the online experiment. 

Concretely, a sequence of linear regression models are fitted to predict the ratings of phi based on the average values of phi. The models includes task_type as an additional predictor to account for possible systematic variations caused by the different task types. 

## 2.1 Simple Linear Regression Models

```{r}
# Defining formulas:
formula_1 <- phi_rating ~ avg_phi + task_type + (1|subj_id)
formula_2 <- phi_rating ~ avg_phi + task_type

# Fitting models:
mdl_1 <- lme4::lmer(formula_1, data = merged_data)
mdl_2 <- lm(formula = formula_2, data = merged_data)

# Reading summaries:
summary(mdl_1)
summary(mdl_2)
```

We can plot the regression line, e.g., from Mdl_2:

```{r}
plot(merged_data$avg_phi, merged_data$phi_rating,
     xlab = "Actual Phi Average Value",
     ylab = "Consciousness Rating",
     main = "Regression Line, Model 2 \nTask Type = Catch")
b_hat <- coef(mdl_2)
abline(a = b_hat[1] + b_hat[3], b = b_hat[2], col = "black")
```
Commenting on the models:

None of these models are especially good to use: Mdl_1 accounts for the repeated measures experimental design by modelling random intercepts for the different subjects. However, the fitting procedure returns an 'is singular' warning, possibly because there is not enough data points for this complicated model. 

Hence, the simpler Mdl_2 is fitted. The problem here is that it does not model the repeated measures design, violating the assumption of independence of error. 

Instead of using these models, I will move on to fitting a linear mixed effects regression model using Bayesian methods (stan_glmer).

## 2.2 Fitting a Bayesian regression model

```{r}
# Setting seed:
set.seed(33)

# Fitting a Bayesian mixed effects model using stan_glmer (with no specified prior, that is a weakly informative prior):
mdl_3 <- stan_glmer(phi_rating ~ avg_phi + task_type + (1|subj_id), data=merged_data, refresh = 0)
print(mdl_3)

# Extracting coefficients and computing a mean slope for the avg_phi coefficient + intercept:
coef_mdl_3 <- coef(mdl_3)
mean_slope_mdl_3 <- mean(coef_mdl_3$subj_id[2]$avg_phi)
mean_intercept_mdl_3 <- mean(coef_mdl_3$subj_id[1]$`(Intercept)`) 
mean_type_mdl_3 <- mean(coef_mdl_3$subj_id[3]$task_typecatch)

# Plotting a random selection of estimated regression lines (using a script modeled on the one shown on pp. 156-157 in Gelman et al., 2020):
print(mdl_3)
sims_3 <- as.matrix(mdl_3)
n_sims_3 <- nrow(sims_3)
subset <- sample(n_sims_3, 20)
plot(merged_data_2$avg_phi, merged_data$phi_rating,
     xlab="Actual Phi Average Value", 
     ylab="Consciousness Rating",
     main = "Regression Line Samples, Model 3 \nTask Type = Catch")
for (i in subset){
  abline(sims_3[i,1] + sims_3[i,3], sims_3[i,2], col="grey")
}
abline(a = mean_intercept_mdl_3 + mean_type_mdl_3, b = mean_slope_mdl_3, col = "blue")

# Extracting confidence intervals or uncertainty intervals for the phi rating slope from mdl_3:
CI_mdl_3 <- quantile(sims_3[,2], c(0.025, 0.975))
CI_mdl_3_intercept <- quantile(sims_3[,1], c(0.025, 0.975))

# Seeing the distribution of estimates:
sims_3_df <- data.frame(sims_3)

# Plotting the distribution of estimates:
ggplot(data = sims_3_df, aes(x = avg_phi)) +
  geom_density(fill = "blue", alpha = 0.2) +
  geom_vline(xintercept = mean(sims_3_df$avg_phi)) +
  geom_vline(xintercept = CI_mdl_3[[1]], linetype = "dashed") +
  geom_vline(xintercept = CI_mdl_3[[2]], linetype = "dashed") +
  labs(x = "Avg. Phi Coefficient Estimates") +
  ggtitle("Posterior Distribution of Avg. Phi Coefficient Estimates from Model 3") +
  annotate("text", x = c(CI_mdl_3[[1]] + 0.5, mean_slope_mdl_3 + 0.5, CI_mdl_3[[2]] + 0.5), y = 0.25, label = c("-2 SE", "Mean", "+2 SE"),
           color = "Black", vjust = 0, size = 3)
```
```{r}
# Printing the confidence interval for the phi_rating coefficient:
round(CI_mdl_3, digits = 3)
```



```{r}
# Plotting the residuals:
plot(merged_data$avg_phi, residuals(mdl_3),
     xlab = "Avg. Phi",
     ylab = "Model 3 Residuals", 
     main = "Residual Plot, Model 3")
abline(a = mean(residuals(mdl_3)) + sd(residuals(mdl_3)), b = 0, col = "grey")
abline(a = mean(residuals(mdl_3)), b = 0)
abline(a = mean(residuals(mdl_3)) - sd(residuals(mdl_3)), b = 0, col = "grey")
```

## 2.3 Fitting a model with flat priors

Model 3 had weakly informative (default setting) priors. It would be interesting to see how a model with flat priors work: 

```{r}
mdl_4 <- stan_glmer(phi_rating ~ avg_phi + task_type + (1|subj_id), data = merged_data, refresh = 0, prior_intercept = NULL, prior = NULL, prior_aux = NULL)

# Comparing the outputs
print(mdl_4)
print(mdl_3)
```

Judging from the summary statistics, the Bayesian model seems to reach similar estimates regardless of having been given flat priors.


# 3. New alternative regression model using direction switches

Based on the qualitative reports from the experiment, it seems that many participants based their consciousness ratings on the animat's direction switching behavior (which might not be directly related to phi). It would be interesting to make a new regression analysis using direction switch as the independent variable and the consciousness rating as the predictor. 

## 3.1 Computing direction switches

```{r}
task_4_data <- read_csv(file = "/Users/christianstenbro/AU/3_sem/Perception_and_Action/Integrated Information Theory/phi-surprisal/processed_data/timestep_data_task4.csv")
```

```{r}
# Extracting the timestep data for the specific runs constituting the stimuli battery:
timestep_subset_loop <- data.frame()

for (i in seq(1:nrow(battery_data))){
  subset_data <- filter(.data = task_4_data, 
                            run == battery_data$run[i], 
                            agent == battery_data$agent[i],
                            trial == battery_data$trial[i])
  timestep_subset_loop <- rbind(timestep_subset_loop, subset_data)
}
timestep_subset <- timestep_subset_loop
```

```{r}
# Creating a unique identifier vector to append to the timestep_subset data frame:
id <- data.frame(rep(1:20, each = 33))

# Checking dimensions of the two objects:
nrow(timestep_subset)
nrow(id)

# Merging data objects:
timestep_subset <- cbind(timestep_subset, id)
timestep_subset <- timestep_subset %>% rename(id = rep.1.20..each...33.)
timestep_subset <- timestep_subset %>% relocate(id, .before = run)

# Computing direction switches:
timestep_subset <- timestep_subset %>% 
  mutate(movement_state = ifelse(M1 == 1 & M2 == 1, 0,
                                 ifelse(M1 == 1 | M2 ==1, 1, 0)))
timestep_subset <- timestep_subset %>%
  group_by(group = rep(1:ceiling(n()/33), each = 33, length.out = n())) %>%
  mutate(movement_sequence = data.table::rleid(movement_state))

direction_changes <- timestep_subset %>%
  filter(movement_state == 1) %>%
  group_by(id) %>% 
  summarise(total_direction_changes = n_distinct(movement_sequence))

# Extracting the run, agent, and trial information:
timestep_subset_one_in_each <- timestep_subset %>% 
  group_by(id) %>% 
  sample_n(1) %>% 
  ungroup() %>% 
  select(id, run, agent, trial)

timestep_subset_direction <- timestep_subset_one_in_each %>% 
  left_join(direction_changes, by = "id")

# Merging this with the (standardized) experimental data:
merged_data_direction <- left_join(merged_data, timestep_subset_direction, by = c("run", "agent", "trial"))
```

Now we can plot the ratings against total direction changes:

```{r}
merged_data_direction %>% 
  ggplot(aes(x = total_direction_changes, y = phi_rating, color = variable)) +
  geom_point()

merged_data_direction %>% 
  ggplot(aes(x = total_direction_changes, y = phi_rating, color = subj_id, group = subj_id)) + 
  geom_line()
```
Which also does not reveal any immediate pattern.

## 3.2 Regression

Making a new regression model including the new variable: 

```{r}
set.seed(33)

mdl_5 <- stan_glmer(phi_rating ~ total_direction_changes + avg_phi + task_type + (1|subj_id), data = merged_data_direction, refresh = 0)

merged_data_direction

print(mdl_5)
```
Visualizing the coefficients from model 5 and computing confidence intervals:

```{r}
# Setting seed:
set.seed(33)

# Extracting coefficients and computing a mean slope for the phi_rating coefficient + intercept:
coef_mdl_5 <- coef(mdl_5)
mean_slope_mdl_5_direction <- mean(coef_mdl_5$subj_id[2]$total_direction_changes)
mean_slope_mdl_5_phi <- mean(coef_mdl_5$subj_id[3]$avg_phi)
mean_intercept_mdl_5 <- mean(coef_mdl_5$subj_id[1]$`(Intercept)`)
mean_type_mdl_5 <- mean(coef_mdl_5$subj_id[4]$task_typecatch)

# Plotting a random selection of estimated regression lines (using a script modeled on the one shown on pp. 156-157 in Gelman et al., 2020):
sims_5 <- as.matrix(mdl_5)
n_sims_5 <- nrow(sims_5)
subset <- sample(n_sims_5, 20)
plot(merged_data_direction$avg_phi, merged_data_direction$phi_rating,
     xlab="Avg_Phi Rating", 
     ylab="Conciousness Rating",
     main = "Regression Line Samples, Model 5 \nTask Type = Catch")
for (i in subset){
  abline(sims_5[i,1] + sims_5[i,4], sims_5[i,2] + sims_5[i,3], col="grey")
}
abline(a = mean_intercept_mdl_5 + mean_type_mdl_5, mean_slope_mdl_5_direction + mean_slope_mdl_5_phi, col = "blue")

# Extracting confidence intervals or uncertainty intervals for the phi rating slope from mdl_5:
CI_mdl_5_direction <- quantile(sims_5[,2], c(0.025, 0.975))
CI_mdl_5_avg_phi <- quantile(sims_5[,3], c(0.025, 0.975))

# Seeing the distribution of estimates:
sims_5_df <- data.frame(sims_5)

# Plotting the distribution of estimates:
ggplot(data = sims_5_df, aes(x = total_direction_changes)) +
  geom_density(fill = "blue", alpha = 0.2) +
  geom_vline(xintercept = mean(sims_5_df$total_direction_changes)) +
  geom_vline(xintercept = CI_mdl_5[[1]], linetype = "dashed") +
  geom_vline(xintercept = CI_mdl_5[[2]], linetype = "dashed") +
  ggtitle("Posterior Distribution of Total Dir. Changes Coefficient Estimates from Model 5") +
  labs(x = "Total Direction Changes Coefficient Estimate") +
  #ggtitle("Posterior Distribution of Total Direction Changes Coefficient Estimates from Model 5") +
  annotate("text", x = c(CI_mdl_5_direction[[1]] + 0.1, mean_slope_mdl_5 + 0.1, CI_mdl_5_direction[[2]] - 0.1), y = 1, label = c("-2 SE", "Mean", "+2 SE"),
           color = "Black", vjust = 0, size = 3)
```

# 4. Evaluating model fit

The last thing that would be good to do is to evaluate the fit, e.g., by looking into sigma (which is rather large):

```{r}
# Printing mdl summaries:
print(mdl_3)
print(mdl_5)

# Printing sigma
sigma(mdl_3)
sigma(mdl_5)

# Printing coefficient CI:
cat("Mdl_3 CI avg_phi coefficient: ",
round(CI_mdl_3, digits = 3))

cat("Mdl_3 CI intercept: ",
round(CI_mdl_3_intercept, digits = 3))

cat("\nMdl_5 CI total_direction_changes coefficient: ",
round(CI_mdl_5_direction, digits = 3))

cat("\nMdl_5 CI avg_phi coefficient: ",
round(CI_mdl_5_avg_phi, digits = 3))
```

## 4.1 Predicting for new hypothetical data points based on mdl_3 to get a sense for the uncertainty in the model

Trying out some prediction stuff:

```{r Predictions based on mdl_3 with medium value of phi}
# Setting seed:
set.seed(33)

# Setting parameters and saving as new data objects:
subj_id = 1
avg_phi = 1
task_type = "avoid"
new <- data.frame(subj_id, avg_phi, task_type)

# Predicting from the posterior distribution, mdl_3:
y_post_pred <- posterior_predict(mdl_3, newdata = new)

# Computing statistics and plotting the distribution of possible of consciousness ratings based on the new data and model 3:
mean(y_post_pred)
sd(y_post_pred)

plot(density(y_post_pred),
     main = "Uncertainty of a Model 3 Prediction \n New data point of task type 'avoid', with avg. phi = 1", 
     cex.main = 0.9,
     xlab = "Consciousness Rating Value Prediction",
     cex.lab = 0.8)
```
```{r Predictions based on mdl_3 with max value of phi}
# Setting seed:
set.seed(33)

# Setting parameters and saving as new data objects:
subj_id = 1
avg_phi = max(merged_data$avg_phi)
task_type = "avoid"
new <- data.frame(subj_id, avg_phi, task_type)

print(round(avg_phi, digits = 3))

# Predicting from the posterior distribution, mdl_3:
y_post_pred <- posterior_predict(mdl_3, newdata = new)

# Computing statistics and plotting the distribution of possible of consciousness ratings based on the new data and model 3:
mean(y_post_pred)
sd(y_post_pred)

plot(density(y_post_pred),
     main = "Uncertainty of a Model 3 Prediction \n New data point of task type 'avoid', with avg. phi = 2.519", 
     cex.main = 0.9,
     xlab = "Consciousness Rating Value Prediction",
     cex.lab = 0.8)
```

```{r Predictions based on mdl_5, low number of direction changes}
# Setting seed:
set.seed(33)

# Setting parameters and saving as new data objects:
subj_id = 1
total_direction_changes = 1
task_type = "avoid"
new <- data.frame(subj_id, total_direction_changes, task_type)

# Predicting from the posterior distribution, mdl_5:
y_post_pred <- posterior_predict(mdl_5, newdata = new)

# Computing statistics and plotting the distribution of possible of consciousness ratings based on the new data and model 3:
mean(y_post_pred)
sd(y_post_pred)

plot(density(y_post_pred),
     main = "Uncertainty of a Model 5 Prediction \n New data point of task type 'avoid', with total direction changes = 1", 
     cex.main = 0.9,
     xlab = "Consciousness Rating Value Prediction",
     cex.lab = 0.8)
```
```{r Predictions based on mdl_5, max number of direction changes}
# Setting seed:
set.seed(33)

# Setting parameters and saving as new data objects:
subj_id = 1
total_direction_changes = max(merged_data_direction$total_direction_changes)
task_type = "avoid"
new <- data.frame(subj_id, total_direction_changes, task_type)

# Predicting from the posterior distribution, mdl_5:
y_post_pred <- posterior_predict(mdl_5, newdata = new)

# Computing statistics and plotting the distribution of possible of consciousness ratings based on the new data and model 3:
mean(y_post_pred)
sd(y_post_pred)

plot(density(y_post_pred),
     main = "Uncertainty of a Model 5 Prediction \n New data point of task type 'avoid', with total direction changes = 12", 
     cex.main = 0.9,
     xlab = "Consciousness Rating Value Prediction",
     cex.lab = 0.8)
```

## 4.2 Estimating explained variance using Bayesian R2 (pp. 170-171 in Gelman et al.)

```{r}
# Setting seed:
set.seed(33)

# Computing Bayesian R2:
mdl_3_R2 <- bayes_R2(mdl_3)
mdl_5_R2 <- bayes_R2(mdl_5)

# Printing R2 statistics:
cat("R2 median and SD (rounded to 3 digits):\n\n",
    "Median R2 mdl_3: ", round(median(mdl_3_R2), 3), 
    "\nSD of R2: ", round(sd(mdl_3_R2), 3),
    "\n\nMedian R2 mdl_5: ", round(median(mdl_5_R2), 3),
    "\nSD of R2: ", round(sd(mdl_5_R2), 3), "\n"
    )

# Cross validation (could be relevant for model selection, but I haven't really done any quantitative model selection)
loo(mdl_5)
loo(mdl_3)
```

# References

Gelman, A., Hill, J., & Vehtari, A. (2020). Regression and Other Stories (1st ed.). Cambridge University Press. https://doi.org/10.1017/9781139161879